# Spark Practice  

- Spark, Hadoop, [Hive], python, jupyter lab  
- spark standalone cluster  
  
This project is aim for creating spark exercise environment and making spark getting-started guide which is able to run purely within this project.  
  
>  
> ***Now constructing ...***  
>  

### Pre-requisite

- Ubuntu 18.04 (docker)
- RAM >= 8 GB  

## Index  

1. Prepare practice environment(machine)
 - local VM
 - GCP VM   
2. Spark local mode with minimum installation (pyspark + Jupyter)
3. Spark remote client mode connection with minimum pyspark client
4. Spark local mode + Hdfs + Hive   
5. Spark Cluster mode : simple installation (Docker-compose. bitnami container image)  
6. Spark cluster + kafka  
7. Spark cluster + Ignite 
8. Spark Cluster + Hdfs + Hive manual installation  
9. Oozie installation 
10. Zeppelin installation  

  
At this time you can run this cluster 
  