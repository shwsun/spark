{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01985d71-d0ba-46fc-ae43-2b361adc5308",
   "metadata": {},
   "source": [
    "# 일반 구매 차감 \n",
    "1000만 세톱 데이터에 대해 일반 구매 차감 연산 실행한 결과  \n",
    " - 전체 : 94 초  \n",
    " - 세션 생성 : 23 초  \n",
    " - 차감 계산 : 37 초 (14초.캐시)    \n",
    " - 스냅샷 저장 : 32 초  \n",
    " - 결과 확인 : 2 초  \n",
    " - 요약 결과 생성 : \n",
    " - 요약 rdb 기록 : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0657f239-2675-409d-820d-2ab11bb449d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 라이브러리 임포트  \n",
    "import socket\n",
    "import sys\n",
    "import os\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row, SparkSession\n",
    "from os.path import abspath\n",
    "import findspark\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c16fd2f-27cc-4493-83b7-53d4762537f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경변수 정의  \n",
    "scale = 1000 # 1000 만 건 수준\n",
    "PRJ_ROOT = '/user/root'\n",
    "APP_NAME = '03-01_plain-ad-calc'\n",
    "DB_NAME = 'inven'\n",
    "\n",
    "# 데이터의 파일 포맷 및 파일명  \n",
    "tbl_setop_name = 'inven/table-set-6m-20-1000'\n",
    "file_format = 'parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d6d1dd4-e8d4-4a9b-a8d7-3c132f54f7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스파크 생성 \n",
    "def spark_creation():\n",
    "    spark = SparkSession.builder.master('yarn').appName(APP_NAME)\\\n",
    "    .config('spark.driver.cores', '2').config('spark.driver.memory', '2g')\\\n",
    "    .config('spark.num.executors', '2')\\\n",
    "    .config('spark.executor.cores', '2').config('spark.executor.memory', '4g')\\\n",
    "    .config('spark.jars', '/hive-bin/lib/mysql-connector-java-5.1.49-bin.jar')\\\n",
    "    .config('spark.driver.extraClassPath', '/hive-bin/lib/mysql-connector-java-5.1.49-bin.jar').getOrCreate()\n",
    "    sc = spark.sparkContext\n",
    "    sc\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79911c4d-b827-40f8-9ccd-cb1180d3bb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root   1006906 Mar 17 01:30 mysql-connector-java-5.1.49-bin.jar\n",
      "-rw-r--r-- 1 root staff    10476 Nov 15  2018 mysql-metadata-storage-0.12.0.jar\n"
     ]
    }
   ],
   "source": [
    "!ls -l /hive-bin/lib | grep mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1fd0b5ee-33b2-4c03-8fde-16c4a011adbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.8 ms, sys: 9.73 ms, total: 27.5 ms\n",
      "Wall time: 16 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pyspark/context.py:238: FutureWarning: Python 3.6 support is deprecated in Spark 3.2.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "spark = spark_creation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8dfe5a-5097-4cf9-9670-e019e7e124c6",
   "metadata": {},
   "source": [
    "## 전체 구매 차감  \n",
    "모든 세탑에 (지정 비율 * 구매 단위) 값을 차감  \n",
    "- 인벤토리 기준 정보 조회  \n",
    "- setop 별 비율대로 구매 시간을 반영해서(1 미만 값 등 추가 고민 필요) 차감 데이터 생성 \n",
    "- 인벤시간에서 차감 데이터를 차감  \n",
    "- 차감 결과를 이용해 시간, 지역, 타겟별 잔여 리포트 생성  \n",
    "  \n",
    "원본 비율을 계속 적용하면 남는 시간이 부족해서 차감 안되는 일이나, 처음부터 비율이 낮아서 판매시간 곱해도 1이 안 되는 오차가 계속 발생할 것으로 추정  \n",
    "- (구매시간 * )잔여시간 계산 값에 일정비율?을 적용해야 차감총액이 구매시간이 될지를 찾아서, 일정비율을 적용하는 방법   \n",
    "- 비율*구매시간 결과 중 정수 계산으로 1 이상의 총합이 구매시간이 되도록 비율 가중치를 찾는 방법  \n",
    "  \n",
    "***임시처리***  \n",
    "- 반올림으로 차감 수량 결정(오차 일단 무시) \n",
    "- 부족분 분배...  (비율, 남은 수량 으로 빠르게 계산할 방법...)  \n",
    "\n",
    "## 중요  \n",
    "- 오차 범위가 큰 부족분 먼저 처리  \n",
    "- 비율 오차 처리는 내림 계산을 기본으로 나머지 차액을 회귀식으로 최소오차 비율 찾아서 일괄 적용.   \n",
    " -> 잔여가 1 남지 않은 수량을 제외하고 계산...  \n",
    "  - 1. 내림 결과,  2. 부족분 계산, 3. 비율 오차 처리  \n",
    "  - 1. 총량 계산 \n",
    "  - 2. 부족 여부 판단 (6개월분 각각? 전체? 판단 필요)   \n",
    "  - 3. (반올림) 비율 계산 결과 적용 - (-) 가능  \n",
    "  - 4. 총량 0이 아닌 세톱 모두 조회  \n",
    "  - 5. 0<x 인 로우만 조회해서 남은 비율 계산.  \n",
    "  - 6. (-) 수량 * 전체 잔여 * 5 비율 적용. -> (-)는 모두 0이 되고, 나머지는 추가 차감.  \n",
    "  - 6개월분 모두 적용  \n",
    "\n",
    "  \n",
    ">- 내림값 총합에서 남는 값을 \n",
    ">- 차감 부족분을 어떻게 분배할 지 ...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "533a5275-d108-4171-9c89-677aeb6158d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.14 ms, sys: 0 ns, total: 4.14 ms\n",
      "Wall time: 2.41 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "## 인벤 기준 정보 조회  \n",
    "spark.read.format(file_format).load(tbl_setop_name).createOrReplaceTempView('setop_view')\n",
    "spark.catalog.cacheTable(\"setop_view\")\n",
    "spark.catalog.isCached('setop_view')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "640ec03b-e71b-46a8-affb-3b300c137c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-------------+\n",
      "|summary|       setop|          qty|\n",
      "+-------+------------+-------------+\n",
      "|  count|          10|           10|\n",
      "|   mean|        null|20.0000000000|\n",
      "| stddev|        null|          0.0|\n",
      "|    min|ST_A_0000000|    20.000000|\n",
      "|    25%|        null|         20.0|\n",
      "|    50%|        null|         20.0|\n",
      "|    75%|        null|         20.0|\n",
      "|    max|ST_A_0000009|    20.000000|\n",
      "+-------+------------+-------------+\n",
      "\n",
      "CPU times: user 1.53 ms, sys: 3.15 ms, total: 4.69 ms\n",
      "Wall time: 1.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "id = \"ST_A_000000%\"\n",
    "qty = 2\n",
    "df_tmp = spark.sql(str.format(\"select setop, inv_val_01 *({}/100.0) qty from setop_view where setop like '{}'\", qty, id))\n",
    "#df_tmp.to_table('inven.my_table', partition_cols='setop')\n",
    "df_tmp.createOrReplaceTempView('setop_temp')\n",
    "df_tmp.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "498da6cd-f708-4e7f-99f2-0e71c23551d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.28 ms, sys: 1.09 ms, total: 10.4 ms\n",
      "Wall time: 4.37 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(summary='count', setop='10', inv_val_01='10'),\n",
       " Row(summary='mean', setop=None, inv_val_01='980.0000000000'),\n",
       " Row(summary='stddev', setop=None, inv_val_01='0.0'),\n",
       " Row(summary='min', setop='ST_A_0000000', inv_val_01='980.000000'),\n",
       " Row(summary='25%', setop=None, inv_val_01='980.0'),\n",
       " Row(summary='50%', setop=None, inv_val_01='980.0'),\n",
       " Row(summary='75%', setop=None, inv_val_01='980.0'),\n",
       " Row(summary='max', setop='ST_A_0000009', inv_val_01='980.000000')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# inv_val_01*({}/100.0)\n",
    "all_sql = \"\"\"\n",
    "select setop, sum(inv_val_01) inv_val_01 \n",
    "from \n",
    "(\n",
    "    select setop, inv_val_01 from setop_view where setop like 'ST_A_000000%'\n",
    "    UNION ALL \n",
    "    select setop, -qty inv_val_01 from setop_temp \n",
    ") \n",
    "group by setop \n",
    "\"\"\"\n",
    "# spark.sql(all_sql).show()\n",
    "# spark.sql(all_sql).summary().show()\n",
    "spark.sql(all_sql).summary().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "248c83b7-2118-43f6-b7cb-5f0930c6efb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+--------------+\n",
      "|summary|       setop|    inv_val_01|\n",
      "+-------+------------+--------------+\n",
      "|  count|         100|            10|\n",
      "|   mean|        null|980.0000000000|\n",
      "| stddev|        null|           0.0|\n",
      "|    min|ST_A_0000000|    980.000000|\n",
      "|    25%|        null|         980.0|\n",
      "|    50%|        null|         980.0|\n",
      "|    75%|        null|         980.0|\n",
      "|    max|ST_A_0000099|    980.000000|\n",
      "+-------+------------+--------------+\n",
      "\n",
      "CPU times: user 803 µs, sys: 4.69 ms, total: 5.49 ms\n",
      "Wall time: 4.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# inv_val_01*({}/100.0)\n",
    "all_sql = \"\"\"\n",
    "select setop_view.setop setop, setop_view.inv_val_01+b.inv_val_01 inv_val_01 \n",
    "--select  setop_view.setop setop, setop_view.inv_val_01, b.inv_val_01 inv_val_01 \n",
    "from setop_view LEFT OUTER JOIN ( select setop, -qty inv_val_01 from setop_temp) b \n",
    "ON (setop_view.setop = b.setop) \n",
    "where setop_view.setop like 'ST_A_00000%'\n",
    "\"\"\"\n",
    "spark.sql(all_sql).summary().show()\n",
    "# spark.sql(all_sql).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74094953-5019-4243-9cba-8f5ad73fb2ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "172805bf-28e3-46ec-8a4e-6ed91e3dcdc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(setop='ST_B_0499136')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# row = spark.sql(\"select * from setop_view limit 5\").select(\"setop\").take(1)\n",
    "# row[0].asDict()[\"setop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b410891-fceb-4efe-a2d3-f7e4b3dca2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+---------------+---------------+---------------+---------------+\n",
      "|sum(inv_val_01)|sum(inv_val_02)|sum(inv_val_03)|sum(inv_val_04)|sum(inv_val_05)|sum(inv_val_06)|\n",
      "+---------------+---------------+---------------+---------------+---------------+---------------+\n",
      "|    10000000000|    10000000000|    10000000000|    10000000000|    10000000000|    10000000000|\n",
      "+---------------+---------------+---------------+---------------+---------------+---------------+\n",
      "\n",
      "CPU times: user 10.2 ms, sys: 982 µs, total: 11.2 ms\n",
      "Wall time: 26.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 1) 총량 계산 : 최초 24 초. 재실행 시 1초 미만. \n",
    "sql_total = \"select sum(inv_val_01), sum(inv_val_02), sum(inv_val_03), sum(inv_val_04), sum(inv_val_05), sum(inv_val_06) from setop_view\"\n",
    "spark.sql(sql_total).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2f8f6f2-f5b0-475d-8886-758575d69141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.3.4-cp36-cp36m-manylinux1_x86_64.whl (11.5 MB)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.3.1)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-8.4.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "     |################################| 3.1 MB 1.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.19.5)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (3.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.1->matplotlib) (1.11.0)\n",
      "Installing collected packages: pillow, matplotlib\n",
      "Successfully installed matplotlib-3.3.4 pillow-8.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install numpy pandas\n",
    "#!python3 -m pip install -U pip\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0d74802b-4edf-4916-bdfb-320f46b27718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2) 부족 여부 판단. 생략 ... \n",
    "# # 아래는 총합 100% 근사한 분포수 생성  \n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt  \n",
    "\n",
    "# cnt = 10000*1000\n",
    "# rates = np.random.normal(loc=2/cnt*50, scale=1/cnt, size=cnt)\n",
    "# plt.hist(rates)\n",
    "# print(sum(rates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "730e5f5d-7ebc-4105-b074-fe4f30b8cd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|          inv_val_01|          inv_val_02|          inv_val_03|          inv_val_04|          inv_val_05|          inv_val_06|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|-0.00999999977654...|-0.00999999977654...|-0.00999999977654...|-0.00999999977654...|-0.00999999977654...|-0.00999999977654...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n",
      "CPU times: user 0 ns, sys: 4.17 ms, total: 4.17 ms\n",
      "Wall time: 2.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# 3) 비율 계산 반올림  \n",
    "pcnt = 1000*1000*10 # 100 이어야 하지만 1천만건 하드 코딩 비율 조정 위해 임시값. \n",
    "sql_total = f\"select setop, -(inv_val_01*inv_rate_01/{pcnt}) inv_val_01, -(inv_val_02*inv_rate_02/{pcnt}) inv_val_02, -(inv_val_03*inv_rate_03/{pcnt}) inv_val_03\\\n",
    ", -(inv_val_04*inv_rate_04/{pcnt}) inv_val_04, -(inv_val_05*inv_rate_05/{pcnt}) inv_val_05, -(inv_val_06*inv_rate_06/{pcnt}) inv_val_06 from setop_view\"\n",
    "sql_all = f\"select sum(inv_val_01) inv_val_01, sum(inv_val_02) inv_val_02, sum(inv_val_03) inv_val_03\\\n",
    ", sum(inv_val_04) inv_val_04, sum(inv_val_05) inv_val_05, sum(inv_val_06) inv_val_06 from ({sql_total}) as AL\"\n",
    "\n",
    "spark.sql(sql_all).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94d24274-a790-4d61-91e8-ce54b20d841c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.43 ms, sys: 450 µs, total: 2.88 ms\n",
      "Wall time: 159 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 3) 차감 계산  \n",
    "sql_calc = f\"select setop, sum(inv_val_01) inv_val_01 , sum(inv_val_02) inv_val_02, sum(inv_val_03) inv_val_03\\\n",
    ", sum(inv_val_04) inv_val_04 , sum(inv_val_05) inv_val_05, sum(inv_val_06) inv_val_06 \\\n",
    "from ( \\\n",
    "{sql_total} \\\n",
    "UNION ALL \\\n",
    "select setop, inv_val_01, inv_val_02, inv_val_03, inv_val_04, inv_val_05, inv_val_06 from setop_view \\\n",
    ") as AL \\\n",
    "group by setop\"\n",
    "#spark.sql(sql_calc).count()\n",
    "spark.sql(sql_calc).createOrReplaceTempView(\"tbl_subtracted\")\n",
    "# 차감 스냅샷 기록  \n",
    "# ...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "799e030a-f2ee-439a-a33b-9ddc8117c9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 188 µs, sys: 2.92 ms, total: 3.11 ms\n",
      "Wall time: 76.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 4) 총량 0이 아닌 세톱 조회  \n",
    "spark.sql(\"select * from tbl_subtracted where inv_val_01>0 or inv_val_02>0 or \\\n",
    "inv_val_03>0 or inv_val_04>0 or inv_val_05>0 or inv_val_06>0 \").createOrReplaceTempView(\"tbl_remains\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20cb46bc-600b-40c9-9753-b550700369ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.5 ms, sys: 477 µs, total: 2.97 ms\n",
      "Wall time: 113 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 5) 남은 비율 계산 : 42 초    \n",
    "# 5-1) (-) 수량. 일단 하드 코딩 \n",
    "#spark.sql(\"select 1000 inv_val_01, 900 inv_val_02, 950 inv_val_03, 850 inv_val_04, 810 inv_val_05, 890 inv_val_06\").createOrReplaceTempView(\"remains_qty\")\n",
    "remains = [1000, 900, 950, 850, 880, 890]\n",
    "totals = \"\"\"select \n",
    "sum(inv_val_01) inv_val_01, sum(inv_val_02) inv_val_02, sum(inv_val_03) inv_val_03\n",
    ", sum(inv_val_04) inv_val_04, sum(inv_val_05) inv_val_05, sum(inv_val_06) inv_val_06 \n",
    "from tbl_remains\n",
    "\"\"\"\n",
    "spark.sql(totals).createOrReplaceTempView(\"totals\")\n",
    "# 5-2) 도수 / 남은 총량. 남은 수량을 차감할 비율. \n",
    "sql_minus_remains = f\"\"\"\n",
    "select setop\n",
    ", -{remains[0]}*tbl_remains.inv_val_01/totals.inv_val_01 inv_val_01, -{remains[1]}*tbl_remains.inv_val_02/totals.inv_val_02 inv_val_02 \n",
    ", -{remains[2]}*tbl_remains.inv_val_03/totals.inv_val_03 inv_val_03, -{remains[3]}*tbl_remains.inv_val_04/totals.inv_val_04 inv_val_04 \n",
    ", -{remains[4]}*tbl_remains.inv_val_05/totals.inv_val_05 inv_val_05, -{remains[5]}*tbl_remains.inv_val_06/totals.inv_val_06 inv_val_06 \n",
    "from tbl_remains cross join totals \n",
    "\"\"\"\n",
    "spark.sql(sql_minus_remains).createOrReplaceTempView(\"minus_remains\")\n",
    "\n",
    "#spark.sql(\"select * from minus_remains limit 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "389c97e7-2516-4752-be1f-719f8d29fb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.7 ms, sys: 21.5 ms, total: 45.2 ms\n",
      "Wall time: 2min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 6) 추가 차감 및 결과 스냅샷 기록 : 70 초   \n",
    "sql_result = \"\"\"\n",
    "select setop\n",
    ", sum(inv_val_01) inv_val_01 , sum(inv_val_02) inv_val_02\n",
    ", sum(inv_val_03) inv_val_03 , sum(inv_val_04) inv_val_04\n",
    ", sum(inv_val_05) inv_val_05 , sum(inv_val_06) inv_val_06\n",
    "from \n",
    "(\n",
    "select * \n",
    "from tbl_subtracted \n",
    "UNION ALL \n",
    "select * \n",
    "from minus_remains\n",
    ") as A \n",
    "group by setop \n",
    "\"\"\"\n",
    "\n",
    "result = spark.sql(sql_result)\n",
    "result.write.save(path=\"result\", format=file_format, mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6a2554-ff77-4642-b5d5-a221811ddc07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1635bd75-b631-4b7e-9a34-59ebc204ee21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count = 10,000,000\n",
      "CPU times: user 4.12 ms, sys: 930 µs, total: 5.05 ms\n",
      "Wall time: 2.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cnt = spark.read.format(file_format).load('result').count()\n",
    "result.createOrReplaceTempView(\"result\")\n",
    "print(f'Row count = {cnt:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41296c49-63f2-4ac7-8e13-e3888e2b4e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스냅샷에서 차감 리포트 생성  \n",
    "# ...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab6d5521-e13a-4cd7-818d-4810cab4cc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/py4j/clientserver.py\", line 475, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/usr/lib/python3.6/socket.py\", line 586, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mjdbc\u001b[0;34m(self, url, table, mode, properties)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m             \u001b[0mjprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetProperty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# rdb 쓰기 테스트 \n",
    "# conf = SparkConf()  # create the configuration\n",
    "#conf.set(\"spark.jars\", \"/path/to/postgresql-connector-java-someversion-bin.jar\")  # set the spark.jars\n",
    "# --driver-class-path postgresql-9.4.1207.jar --jars postgresql-9.4.1207.jar\n",
    "# /hadoop/share/hadoop/yarn/lib 에 mysql jdbc.jar 넣는다.  \n",
    "props = {\"driver\":\"com.mysql.jdbc.Driver\"}\n",
    "db_url = \"jdbc:mysql://rdb/test_jdbc?user=jdbc&password=jdbc\"\n",
    "tbl = \"from_spark\"\n",
    "result.cache()\n",
    "rdb = spark.sql('select * from result limit 10')\n",
    "rdb.write.jdbc(db_url, tbl, mode='append', properties=props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6377b62-b427-4143-894e-044bcf81be04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jdbcDF = spark.read \\\n",
    "#     .format(\"jdbc\") \\\n",
    "#     .option(\"url\", \"jdbc:postgresql:dbserver\") \\\n",
    "#     .option(\"dbtable\", \"jdbc:postgresql:dbserver\") \\\n",
    "#     .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8388b65d-c6a4-42b9-aef7-42832525b586",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
